# Live3D v2.1 (AttNR) 

Neural Rendering with Attention: An Incremental Improvement for Anime Character Animation

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg) EN](https://colab.research.google.com/github/transpchan/Live3D-v2/blob/main/notebook.ipynb) |
[Draft] | 
[Code](https://github.com/transpchan/Live3D-v2/) |
[Discord](https://discord.gg/Md3cykbn36) |
[Twitter](https://twitter.com/transpchan) |
[Bilibili](https://space.bilibili.com/6418569) |
[Zhihu](https://zhuanlan.zhihu.com/p/565391665)

### Project history


<i>2022/08</i> @transpchan was kicked out from the authors of  [Live3Dv1](https://github.com/transpchan/Live3D) as I refused to continue submittion after seeing the [heart-breaking reviews](https://github.com/transpchan/Live3D) from ECCV22. 

**Call for Authors/Contributors: Please contact me if you are willing to be the author of the paper of v2 and future versions, or if you are willing to sponsor furher research.  Pull requests are also welcome!!**

<i>2022/10</i> Live3Dv2 is released. Changes are (1) dropping the ResNet50 encoder (2) adding self-attention to the U-Net (3) tuning the hyper-parameters of the networks.

<i>2022/11</i> Weight file for Live3Dv2 is released. 

<i>2022/11</i> Stay tuned for [Live3D v3](https://github.com/transpchan/Live3D-v3)

<i>2022/12</i> Weight file for Live3Dv2.1 is released. 
### Try it yourself!


**[Demo1] [Generate videos](https://transpchan.github.io/live3d/#demo1)**

**[Demo2] [Colorize your own model](https://transpchan.github.io/live3d/#demo2)**

**[Demo3] [Generate 3D point cloud from drawings](https://transpchan.github.io/live3d/#demo3)**


![visitor](https://count.getloli.com/get/@live3d?theme=gelbooru)
