# Live3D v2.2 (AttNR) 

Neural Rendering with Attention: An Incremental Improvement for Anime Character Animation

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/transpchan/Live3D-v2/blob/main/notebook.ipynb) [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.7652719.svg)](https://doi.org/10.5281/zenodo.7652719) [![Download](https://img.shields.io/badge/Download-Windows-green.svg)](https://github.com/transpchan/Live3D-v2/releases/windows) [![Code](https://img.shields.io/badge/Code-GPLv3-green.svg)](https://github.com/transpchan/Live3D-v2/) 

[Windows Bundle[^3]](https://github.com/transpchan/Live3D-v2/releases/windows) |
 [一键启动Windows懒人包[^3]](https://github.com/transpchan/Live3D-v2/releases/windows) |
[Discord](https://discord.gg/Md3cykbn36) |
[Twitter](https://twitter.com/transpchan) |
[Youtube (Demo)](https://www.youtube.com/playlist?list=PL7inWxnP31gKeBe2TCDQZIXQpoOTpJgFT) |
[哔哩哔哩](https://space.bilibili.com/6418569) |
[知乎（有干货）](https://zhuanlan.zhihu.com/p/565391665)

[![image](https://github.com/transpchan/transpchan.github.io/blob/main/live3d/main.png?raw=true)](https://www.youtube.com/playlist?list=PL7inWxnP31gKeBe2TCDQZIXQpoOTpJgFT)


### Project history


<i>2022/08</i> @transpchan is no longer author[^1] of  [Live3Dv1 paper](https://github.com/transpchan/Live3D/issues/1#issuecomment-1173902028) . He therefore is no longer involved in the submittion to AAAI, and IJCAI, which is made by other authors alone. 

**Call for Authors/Contributors: Please contact me if you are willing to be the author of the paper of v2 and future versions, or if you are willing to sponsor furher research.  Pull requests are also welcome!!**

<i>2022/10</i> Live3Dv2 is released. Changes are (1) dropping the ResNet50 encoder (2) adding self-attention to the U-Net (3) tuning the hyper-parameters of the networks.

<i>2022/11</i> [Weight file](https://github.com/transpchan/Live3D-v2/releases) for Live3Dv2 is released. 

<i>2022/11</i> Stay tuned for [Live3D v3](https://github.com/transpchan/Live3D-v3)


### Try it yourself!


**[Demo1] Generate videos**

[![image](https://github.com/transpchan/transpchan.github.io/blob/main/live3d/5.gif?raw=true)](https://github.com/transpchan/Live3D-v2)
[![image](https://github.com/transpchan/transpchan.github.io/blob/main/live3d/6.gif?raw=true)](https://github.com/transpchan/Live3D-v2)


**[Demo2[^2]]] Colorize your own model**

[![image](https://github.com/transpchan/transpchan.github.io/blob/main/live3d/4.gif?raw=true)](https://transpchan.github.io/live3d)

**[Demo3] Generate 3D point cloud from drawings**

[![image](https://github.com/transpchan/transpchan.github.io/blob/main/live3d/3.gif?raw=true)](https://github.com/transpchan/Live3D-v2)

![visitor](https://count.getloli.com/get/@live3d?theme=gelbooru)



[^1]: Despite the fact that Live3Dv1 was initially  @transpchan 's personal project, and he is the only person who is actually coding and training Live3Dv1

[^2]: Demo2 is from Live3D-v1 not from v2. Live3D-v2 is better in the quality, try it yourself. Drawings and character design are taken from the MIT-Licenced CoNR maintained by Megvii. 

[^3]:Windows bundle may include third-party binaries that is not distributed with GPLv3. (mostly from conda repo and still open-sourced with other licences)
